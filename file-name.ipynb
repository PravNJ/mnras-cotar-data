{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/praveen/Dropbox/Masters/emission-mnras-cotar/data\"\n",
    "files = [os.path.splitext(filename)[0] for filename in os.listdir(path)]\n",
    "print (files)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1902110022010241', '1902230017012411', '1706030041012351', '1902120016013191', '1611070039013771', '1705080033012212', '1902230017012413', '1705080033012214', '1902100024013022', '1601300036010743', '1601230026010123', '1504290031011624', '1902100016012382', '1902060035010442', '1504290031011623', '1706040021011451', '1902120016013384', '1902110022013603', '1704080050012173', '1403120045011163', '1902240021013511', '1902100024013023', '1704130036010672', '1902110016011483', '1902120016013423', '1902120016013383', '1706040021011452', '1902120016013192', '1601230026010122', '1704130036010673', '1706040021011453', '1504290031011621', '1604220057011512', '1601230026010124', '1902060035010444', '1504290031012681', '1611070039013772', '1902100024010371', '1902120016013194', '1601300036010741', '1902110022013602', '1902120016013513', '1902110022010244', '1902060035010443', '1706040021011454', '1902230017012414', '1704080050012172', '1604220057011514', '1704080050012171', '1504290031012682', '1604220057011513', '1902240021013513', '1902100016012381', '1902110022013604', '1704080050012174', '1604220057011511', '1504290031011622', '1902120016013422', '1902100016012384', '1611070039013774', '1902120016013381', '1611070039013773', '1902110022013601', '1705080033012211', '1902120016013382', '1902110022010242', '1601300036010744', '1902100016012383', '1902120016013511', '1902120016013512', '1902110016011482', '1902240021013514', '1704130036010671', '1601300036010742', '1902100024010374', '1403120045011162', '1706030041012353', '1705080033012213', '1504290031012684', '1902120016013193', '1902110016011484', '1902120016013421', '1601230026010121', '1706030041012352', '1902120016013514', '1902100024010372', '1902240021013512', '1902100024013024', '1902120016013424', '1902060035010441', '1902230017012412', '1704130036010674', '1403120045011164', '1902100024013021', '1902110022010243', '1902110016011481', '1504290031012683', '1403120045011161', '1902100024010373', '1706030041012354']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "type(files)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "suffix_list = []\n",
    "\n",
    "for e in files:\n",
    "    for element in e.split():\n",
    "        if element.endswith(\"3\"):\n",
    "            suffix_list.append(element)\n",
    "\n",
    "print(len(suffix_list))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "type(suffix_list[1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "suffix_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['1902230017012413',\n",
       " '1601300036010743',\n",
       " '1601230026010123',\n",
       " '1504290031011623',\n",
       " '1902110022013603',\n",
       " '1704080050012173',\n",
       " '1403120045011163',\n",
       " '1902100024013023',\n",
       " '1902110016011483',\n",
       " '1902120016013423',\n",
       " '1902120016013383',\n",
       " '1704130036010673',\n",
       " '1706040021011453',\n",
       " '1902120016013513',\n",
       " '1902060035010443',\n",
       " '1604220057011513',\n",
       " '1902240021013513',\n",
       " '1611070039013773',\n",
       " '1902100016012383',\n",
       " '1706030041012353',\n",
       " '1705080033012213',\n",
       " '1902120016013193',\n",
       " '1902110022010243',\n",
       " '1504290031012683',\n",
       " '1902100024010373']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "new_list = [s.strip(\"3\") for s in suffix_list]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "new_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['190223001701241',\n",
       " '160130003601074',\n",
       " '160123002601012',\n",
       " '150429003101162',\n",
       " '190211002201360',\n",
       " '170408005001217',\n",
       " '140312004501116',\n",
       " '190210002401302',\n",
       " '190211001601148',\n",
       " '190212001601342',\n",
       " '190212001601338',\n",
       " '170413003601067',\n",
       " '170604002101145',\n",
       " '190212001601351',\n",
       " '190206003501044',\n",
       " '160422005701151',\n",
       " '190224002101351',\n",
       " '161107003901377',\n",
       " '190210001601238',\n",
       " '170603004101235',\n",
       " '170508003301221',\n",
       " '190212001601319',\n",
       " '190211002201024',\n",
       " '150429003101268',\n",
       " '190210002401037']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(new_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190223001701241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160130003601074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160123002601012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150429003101162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190211002201360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0  190223001701241\n",
       "1  160130003601074\n",
       "2  160123002601012\n",
       "3  150429003101162\n",
       "4  190211002201360"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df.to_csv(\"GALAH_DR3_sobject_ids.csv\", header=False, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from spectres import spectres\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"best_emission_candidates.csv\",header=None)\n",
    "df.columns = [\"sobject_id\"]\n",
    "sobject_ids = df[\"sobject_id\"].to_numpy().tolist()\n",
    "\n",
    "GRID_SIZE = 0.06\n",
    "LOWER_LAMBDA = 6472.5\n",
    "UPPER_LAMBDA = 6740\n",
    "regrid = np.arange(LOWER_LAMBDA, UPPER_LAMBDA, GRID_SIZE) \n",
    "\n",
    "def read_spectra(sobject_id):\n",
    "    fits_files = [[],[],[],[]]\n",
    "    for each_ccd in [1,2,3,4]:\n",
    "        fits_files[each_ccd-1] = glob.glob(\"/home/praveen/Dropbox/Masters/python-code/galah-file-read-test/data/GALAH_DR3/spectra/SPECTRA/\"+str(sobject_id)+str(each_ccd)+\".fits\") #this is reading fits files from file and not downloading directly \n",
    "\n",
    "    spectrum = dict()\n",
    "    for each_ccd in [1,2,3,4]: #GALAH uses indexing from 1 - 4\n",
    "        if fits_files[each_ccd-1]!=[]: #just using zero indexing here \n",
    "            fits = pyfits.open(fits_files[each_ccd-1][0]) \n",
    "            \n",
    "            # Extension 0: Reduced spectrum\n",
    "            # Extension 1: Relative error spectrum\n",
    "            # Extension 4: Normalised spectrum, NB: cut for CCD4\n",
    "\n",
    "            # Extract wavelength grid for the reduced spectrum\n",
    "            start_wavelength = fits[0].header[\"CRVAL1\"]\n",
    "            dispersion       = fits[0].header[\"CDELT1\"]\n",
    "            nr_pixels        = fits[0].header[\"NAXIS1\"]\n",
    "            reference_pixel  = fits[0].header[\"CRPIX1\"]\n",
    "\n",
    "            if reference_pixel == 0:\n",
    "                reference_pixel = 1\n",
    "            spectrum['wave_red_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength) #this is the reduced spectrum \n",
    "\n",
    "            # Extract wavelength grid for the normalised spectrum\n",
    "            start_wavelength = fits[4].header[\"CRVAL1\"]\n",
    "            dispersion       = fits[4].header[\"CDELT1\"]\n",
    "            nr_pixels        = fits[4].header[\"NAXIS1\"]\n",
    "            reference_pixel  = fits[4].header[\"CRPIX1\"]\n",
    "\n",
    "            if reference_pixel == 0:\n",
    "                reference_pixel=1\n",
    "            spectrum['wave_norm_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength) #this is the normalised spectrum \n",
    "\n",
    "            spectrum['sob_red_'+str(each_ccd)]  = np.array(fits[0].data)\n",
    "            spectrum['uob_red_'+str(each_ccd)]  = np.array(fits[0].data * fits[1].data)\n",
    "\n",
    "            spectrum['sob_norm_'+str(each_ccd)] = np.array(fits[4].data)\n",
    "            if each_ccd != 4:\n",
    "                spectrum['uob_norm_'+str(each_ccd)] = np.array(fits[4].data * fits[1].data)\n",
    "            else:\n",
    "                # for normalised error of CCD4, only used appropriate parts of error spectrum\n",
    "                spectrum['uob_norm_4'] = np.array(fits[4].data * (fits[1].data)[-len(spectrum['sob_norm_4']):])\n",
    "\n",
    "            fits.close()\n",
    "        else:\n",
    "            spectrum['wave_red_'+str(each_ccd)] = []\n",
    "            spectrum['wave_norm_'+str(each_ccd)] = []\n",
    "            spectrum['sob_red_'+str(each_ccd)] = []\n",
    "            spectrum['sob_norm_'+str(each_ccd)] = []\n",
    "            spectrum['uob_red_'+str(each_ccd)] = []\n",
    "            spectrum['uob_norm_'+str(each_ccd)] = []\n",
    "    \n",
    "    spectrum['wave_red'] = np.concatenate(([spectrum['wave_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['wave_norm'] = np.concatenate(([spectrum['wave_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['sob_red'] = np.concatenate(([spectrum['sob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['sob_norm'] = np.concatenate(([spectrum['sob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['uob_red'] = np.concatenate(([spectrum['uob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['uob_norm'] = np.concatenate(([spectrum['uob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "\n",
    "    return spectrum \n",
    "    \n",
    "    #returns a 30 \"row\" dict of numpy array per row 'wave_red_x' is the key for the key value pair\n",
    "    #camera 3 will be the more useful canmera for Li spectra \n",
    "\n",
    "def resample_spectra(spectrum, camera, verbose):\n",
    "\n",
    "    spec_resample, spec_errs_resample = spectres(regrid,  spectrum['wave_norm_'+str(camera)], spectrum['sob_norm_'+str(camera)], spec_errs= spectrum['uob_norm_'+str(camera)],verbose=verbose) \n",
    "\n",
    "    return spec_resample, spec_errs_resample\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sobject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131116000501262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131116001001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131118002401234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131118002401396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131118002901052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sobject_id\n",
       "0  131116000501262\n",
       "1  131116001001379\n",
       "2  131118002401234\n",
       "3  131118002401396\n",
       "4  131118002901052"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "sobject_ids = df[\"sobject_id\"].to_numpy().tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import h5py\n",
    "\n",
    "#save the resampled spectra to be used as inputs to the training set\n",
    "hf_spec = h5py.File(\"/data/praveen/resampled_emission_spectra.h5\", \"w\")\n",
    "hf_spec.create_dataset('spectra', data=resampled_spectra_collection['spec_resample'])\n",
    "hf_spec.close()\n",
    "\n",
    "#save the wavelength grid \n",
    "hf_grid = h5py.File(\"/data/praveen/wl_grid.h5\", \"w\")\n",
    "hf_grid.create_dataset('wl_grid', data=regrid)\n",
    "hf_grid.close()\n",
    "\n",
    "#save the error spectra\n",
    "hf_error = h5py.File(\"/data/praveen/resampled_test_errors.h5\", \"w\")\n",
    "hf_error.create_dataset('errors', data=resampled_error_collection['error_resample'])\n",
    "hf_error.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('masters-thesis': conda)"
  },
  "interpreter": {
   "hash": "8aa95240b918af49c0a2ea4560aadedb9cfa623e80e3cd8858f359a82f85c074"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}